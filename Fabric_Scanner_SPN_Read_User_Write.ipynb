{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60107c30",
   "metadata": {},
   "source": [
    "# Fabric Scanner - SPN Read + User Write\n",
    "\n",
    "This notebook demonstrates running the Fabric Scanner with:\n",
    "- **Service Principal (SPN)** for reading from Scanner API\n",
    "- **User authentication** for writing to lakehouse\n",
    "\n",
    "This configuration provides:\n",
    "- Automated scanning with SPN credentials\n",
    "- Individual user accountability for data writes\n",
    "- Principle of least privilege (SPN can be Viewer role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece9c13",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. **Service Principal Setup** (for Scanner API reads):\n",
    "   - Create App Registration in Azure AD\n",
    "   - Add API permissions: Power BI Service ‚Üí `Tenant.Read.All`, `Workspace.Read.All`\n",
    "   - Enable in Power BI Admin Portal ‚Üí \"Allow service principals to use Fabric APIs\"\n",
    "   - Store credentials as environment variables:\n",
    "     - `FABRIC_SP_TENANT_ID`\n",
    "     - `FABRIC_SP_CLIENT_ID`\n",
    "     - `FABRIC_SP_CLIENT_SECRET`\n",
    "\n",
    "2. **User Account** (for lakehouse writes):\n",
    "   - Must have Contributor or Admin role on the lakehouse\n",
    "   - Will be prompted for interactive login during notebook execution\n",
    "\n",
    "3. **Lakehouse Configuration**:\n",
    "   - Attach lakehouse to this notebook\n",
    "   - Note workspace ID and lakehouse ID for upload configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the scanner script\n",
    "%run ./fabric_scanner_cloud_connections.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf23f2",
   "metadata": {},
   "source": [
    "## Configuration: SPN for Reading, User for Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa289e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTHENTICATION CONFIGURATION\n",
    "\n",
    "# Use Service Principal for Scanner API (reads)\n",
    "AUTH_MODE = \"spn\"  # Service Principal for all API reads\n",
    "\n",
    "# Use User Authentication for Lakehouse Uploads (writes)\n",
    "import os\n",
    "os.environ[\"UPLOAD_USE_USER_AUTH\"] = \"true\"  # Enable user auth for uploads\n",
    "\n",
    "# Service Principal credentials (for Scanner API reads)\n",
    "# Set these as environment variables or Fabric secrets\n",
    "TENANT_ID = os.getenv(\"FABRIC_SP_TENANT_ID\", \"<YOUR_TENANT_ID>\")\n",
    "CLIENT_ID = os.getenv(\"FABRIC_SP_CLIENT_ID\", \"<YOUR_CLIENT_ID>\")\n",
    "CLIENT_SECRET = os.getenv(\"FABRIC_SP_CLIENT_SECRET\", \"<YOUR_CLIENT_SECRET>\")\n",
    "\n",
    "# Verify configuration\n",
    "print(\"‚úÖ Configuration:\")\n",
    "print(f\"   Scanner API auth: Service Principal (Tenant: {TENANT_ID[:8]}...)\")\n",
    "print(f\"   Lakehouse upload auth: User Account (interactive login)\")\n",
    "print(f\"   Running in Fabric: {RUNNING_IN_FABRIC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5a712",
   "metadata": {},
   "source": [
    "## Optional: Configure Lakehouse Upload Details\n",
    "\n",
    "If running locally and want to upload to Fabric lakehouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a06de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for local execution with lakehouse upload\n",
    "# Skip this cell if running in Fabric notebook\n",
    "\n",
    "if not RUNNING_IN_FABRIC:\n",
    "    UPLOAD_TO_LAKEHOUSE = True\n",
    "    LAKEHOUSE_WORKSPACE_ID = \"<YOUR_WORKSPACE_ID>\"  # Workspace containing lakehouse\n",
    "    LAKEHOUSE_ID = \"<YOUR_LAKEHOUSE_ID>\"  # Lakehouse ID\n",
    "    LAKEHOUSE_UPLOAD_PATH = \"Files/scanner\"  # Path within lakehouse\n",
    "    \n",
    "    print(\"üì§ Lakehouse upload enabled\")\n",
    "    print(f\"   Workspace: {LAKEHOUSE_WORKSPACE_ID}\")\n",
    "    print(f\"   Lakehouse: {LAKEHOUSE_ID}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Running in Fabric - lakehouse attached automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a94aa",
   "metadata": {},
   "source": [
    "## Initialize Authentication\n",
    "\n",
    "This will:\n",
    "1. Authenticate SPN for Scanner API\n",
    "2. Prompt for user login when first write occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SPN authentication for Scanner API\n",
    "initialize_authentication()\n",
    "\n",
    "print(\"\\n‚úÖ Service Principal authenticated for Scanner API\")\n",
    "print(\"‚ÑπÔ∏è  User authentication will be requested on first lakehouse write\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b45b5",
   "metadata": {},
   "source": [
    "## Run Full Tenant Scan\n",
    "\n",
    "This will:\n",
    "1. Use SPN to call Scanner API (read all workspaces)\n",
    "2. Prompt for user login when saving to lakehouse\n",
    "3. Save results to lakehouse table with user credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full tenant scan with SPN read + User write\n",
    "run_cloud_connection_scan(\n",
    "    enable_full_scan=True,\n",
    "    include_personal=True,\n",
    "    table_name=\"tenant_cloud_connections\"\n",
    ")\n",
    "\n",
    "# Note: On first write, you'll be prompted to authenticate as a user\n",
    "# This provides individual accountability for data writes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c6ee1",
   "metadata": {},
   "source": [
    "## Alternative: Large Shared Tenant Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2066d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For large tenants with rate limiting\n",
    "run_cloud_connection_scan(\n",
    "    enable_full_scan_chunked=True,\n",
    "    max_batches_per_hour=450,\n",
    "    include_personal=True,\n",
    "    group_by_capacity=True,\n",
    "    table_name=\"tenant_cloud_connections\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e2259",
   "metadata": {},
   "source": [
    "## Alternative: Incremental Scan (Last 24 Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental scan with hash optimization\n",
    "run_cloud_connection_scan(\n",
    "    enable_incremental_scan=True,\n",
    "    incremental_hours_back=24,\n",
    "    enable_hash_optimization=True,\n",
    "    table_name=\"tenant_cloud_connections\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3439767",
   "metadata": {},
   "source": [
    "## Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9672e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query results from lakehouse table\n",
    "if RUNNING_IN_FABRIC and SPARK_AVAILABLE:\n",
    "    df = spark.sql(\"SELECT * FROM tenant_cloud_connections LIMIT 10\")\n",
    "    display(df)\n",
    "    \n",
    "    # Show connection summary\n",
    "    summary = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            connector,\n",
    "            COUNT(DISTINCT workspace_id) as workspace_count,\n",
    "            COUNT(*) as connection_count\n",
    "        FROM tenant_cloud_connections\n",
    "        GROUP BY connector\n",
    "        ORDER BY connection_count DESC\n",
    "    \"\"\")\n",
    "    print(\"\\nüìä Connection Summary:\")\n",
    "    display(summary)\n",
    "else:\n",
    "    print(\"Results saved to local files in ./scanner_output/curated/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756627ff",
   "metadata": {},
   "source": [
    "## Benefits of This Configuration\n",
    "\n",
    "‚úÖ **Automated Scanning**: SPN allows unattended scheduled scans  \n",
    "‚úÖ **User Accountability**: All data writes are tracked to individual users  \n",
    "‚úÖ **Least Privilege**: SPN can have Viewer role (read-only), user has write permissions  \n",
    "‚úÖ **Audit Trail**: User authentication provides clear audit log for data modifications  \n",
    "‚úÖ **Separation of Duties**: Different credentials for read vs write operations  \n",
    "\n",
    "## Security Notes\n",
    "\n",
    "- Service Principal credentials should be stored in Azure Key Vault or Fabric secrets\n",
    "- User authentication uses standard Microsoft login flow (MFA supported)\n",
    "- Token caching minimizes login prompts during same session\n",
    "- All API calls respect rate limits and include retry logic"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
